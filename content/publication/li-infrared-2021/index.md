---
title: An infrared and visible image fusion method based on multi-scale transformation
  and norm optimization
authors:
- Guofa Li
- Yongjie Lin
- Xingda Qu
date: '2021-07-01'
publishDate: '2024-11-15T17:07:02.428071Z'
publication_types:
- article-journal
publication: '*Information Fusion*'
doi: 10.1016/j.inffus.2021.02.008
abstract: In this paper, we propose a new infrared and visible image fusion method
  based on multi-scale transformation and norm optimization. In this method, a new
  loss function is designed with contrast fidelity (L2 norm) and sparse constraint
  (L1 norm), and the split Bregman method is used to optimize the loss function to
  obtain pre-fusion images. The final fused base layer is obtained by using a multi-level
  decomposition latent low-rank representation (MDLatLRR) method to decompose the
  pre-fusion images. Then, using the pre-fusion image as the reference, image structure
  similarity (SSIM) is introduced to evaluate the validity of detail information from
  the visible image, and the SSIM is then transformed into a weight map which is applied
  to the optimization method based on L2 norm to generate the final detail fusion
  layer. Our proposed method is evaluated and compared with 18 state-of-the-art image
  fusion methods, both qualitatively and quantitatively on four public datasets (i.e.,
  CVC14 driving dataset, TNO dataset with natural scenarios, RoadScene dataset, and
  whole brain atlas dataset). The results show that our proposed method is generally
  better than the compared methods in terms of highlighting targets and retaining
  effective detail information.
tags:
- Image fusion
- Infrared image
- Visible image
- Intelligent systems
- Pre-fusion image
links:
- name: URL
  url: https://www.sciencedirect.com/science/article/pii/S1566253521000221
---
